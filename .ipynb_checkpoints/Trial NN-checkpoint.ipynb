{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Amr Khaled Zaky <br>\n",
    "Date: 23-10-2019 <br>\n",
    "\n",
    "### My Implementation of Creating a Hand Written Integer Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import helper # Helper class provided for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding our first neural network, It will classify hand written integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=400, out_features=200, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 784 # 28 * 28 images\n",
    "hidden_sizes = [400, 200, 100] # 400 nodes in first hidden layer -> 200 in second -> 100 in third\n",
    "output_size = 10 # Number of possible outputs\n",
    "'''\n",
    "# Building a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                      nn.ReLU(), # We can use sigmoid here but Rectified Linear Unit is more accurate.\n",
    "                      nn.Linear(hidden_sizes[2], output_size),\n",
    "                      nn.Softmax(dim=1)) # Softmax: Normalizes output values to give probabilities\n",
    "'''\n",
    "'''\n",
    "In reality: We will not use the softmax at the end because of python's limitation on floating points and\n",
    "most probabilities will have small values close to zero so we will use the raw output.\n",
    "\n",
    "'''\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # Defining our GPU device\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                      nn.ReLU(), # We can use sigmoid here but Rectified Linear Unit is more accurate.\n",
    "                      nn.Linear(hidden_sizes[2], output_size)).to(dev)\n",
    "model.cuda(dev) # Making our model run on the GPU\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing DataSet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data to be in the range [-1, 1]\n",
    "# Normalize: Takes each pixel and applies the following equation --> (value - mean)/ std\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, ), (0.5, )) #transforms.Normalize((mean), (std)) \n",
    "                             ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of Adam:\n",
    "\n",
    "* Straightforward to implement.\n",
    "* Computationally efficient.\n",
    "* Little memory requirements.\n",
    "* Invariant to diagonal rescale of the gradients.\n",
    "* Well suited for problems that are large in terms of data and/or parameters.\n",
    "* Appropriate for non-stationary objectives.\n",
    "* Appropriate for problems with very noisy/or sparse gradients.\n",
    "* Hyper-parameters have intuitive interpretation and typically require little tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3...  Loss: 1.3880\n",
      "Epoch: 1/3...  Loss: 0.5856\n",
      "Epoch: 1/3...  Loss: 0.4776\n",
      "Epoch: 1/3...  Loss: 0.3904\n",
      "Epoch: 1/3...  Loss: 0.4081\n",
      "Epoch: 1/3...  Loss: 0.3481\n",
      "Epoch: 1/3...  Loss: 0.2907\n",
      "Epoch: 1/3...  Loss: 0.3200\n",
      "Epoch: 1/3...  Loss: 0.3254\n",
      "Epoch: 1/3...  Loss: 0.2964\n",
      "Epoch: 1/3...  Loss: 0.3078\n",
      "Epoch: 1/3...  Loss: 0.2789\n",
      "Epoch: 1/3...  Loss: 0.2314\n",
      "Epoch: 1/3...  Loss: 0.2382\n",
      "Epoch: 1/3...  Loss: 0.2299\n",
      "Epoch: 1/3...  Loss: 0.2363\n",
      "Epoch: 1/3...  Loss: 0.2115\n",
      "Epoch: 1/3...  Loss: 0.2186\n",
      "Epoch: 1/3...  Loss: 0.2155\n",
      "Epoch: 1/3...  Loss: 0.1700\n",
      "Epoch: 1/3...  Loss: 0.2047\n",
      "Epoch: 1/3...  Loss: 0.1823\n",
      "Epoch: 1/3...  Loss: 0.1940\n",
      "Epoch: 2/3...  Loss: 0.0923\n",
      "Epoch: 2/3...  Loss: 0.1557\n",
      "Epoch: 2/3...  Loss: 0.1692\n",
      "Epoch: 2/3...  Loss: 0.1452\n",
      "Epoch: 2/3...  Loss: 0.1782\n",
      "Epoch: 2/3...  Loss: 0.1462\n",
      "Epoch: 2/3...  Loss: 0.1377\n",
      "Epoch: 2/3...  Loss: 0.1566\n",
      "Epoch: 2/3...  Loss: 0.1573\n",
      "Epoch: 2/3...  Loss: 0.1621\n",
      "Epoch: 2/3...  Loss: 0.1484\n",
      "Epoch: 2/3...  Loss: 0.1328\n",
      "Epoch: 2/3...  Loss: 0.1218\n",
      "Epoch: 2/3...  Loss: 0.1398\n",
      "Epoch: 2/3...  Loss: 0.1539\n",
      "Epoch: 2/3...  Loss: 0.1807\n",
      "Epoch: 2/3...  Loss: 0.1471\n",
      "Epoch: 2/3...  Loss: 0.1331\n",
      "Epoch: 2/3...  Loss: 0.1453\n",
      "Epoch: 2/3...  Loss: 0.1431\n",
      "Epoch: 2/3...  Loss: 0.1291\n",
      "Epoch: 2/3...  Loss: 0.1256\n",
      "Epoch: 2/3...  Loss: 0.1324\n",
      "Epoch: 3/3...  Loss: 0.0189\n",
      "Epoch: 3/3...  Loss: 0.1023\n",
      "Epoch: 3/3...  Loss: 0.1015\n",
      "Epoch: 3/3...  Loss: 0.1178\n",
      "Epoch: 3/3...  Loss: 0.1220\n",
      "Epoch: 3/3...  Loss: 0.1243\n",
      "Epoch: 3/3...  Loss: 0.1150\n",
      "Epoch: 3/3...  Loss: 0.1080\n",
      "Epoch: 3/3...  Loss: 0.1289\n",
      "Epoch: 3/3...  Loss: 0.1023\n",
      "Epoch: 3/3...  Loss: 0.0994\n",
      "Epoch: 3/3...  Loss: 0.1196\n",
      "Epoch: 3/3...  Loss: 0.0791\n",
      "Epoch: 3/3...  Loss: 0.0910\n",
      "Epoch: 3/3...  Loss: 0.1109\n",
      "Epoch: 3/3...  Loss: 0.1032\n",
      "Epoch: 3/3...  Loss: 0.1028\n",
      "Epoch: 3/3...  Loss: 0.1104\n",
      "Epoch: 3/3...  Loss: 0.1160\n",
      "Epoch: 3/3...  Loss: 0.0882\n",
      "Epoch: 3/3...  Loss: 0.1284\n",
      "Epoch: 3/3...  Loss: 0.1168\n",
      "Epoch: 3/3...  Loss: 0.1166\n",
      "Epoch: 3/3...  Loss: 0.1021\n"
     ]
    }
   ],
   "source": [
    "# Using Cross Entropy For Loss Function and Stochastic Gradient Descent or Adam for Optimizing Weights:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 3\n",
    "print_every = 40\n",
    "steps = 0\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        images = images.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], images[0].shape[1]*images[0].shape[2])\n",
    "        \n",
    "        optimizer.zero_grad() # Clear the gradients as gradients are accumulated\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels) # Calculate the loss\n",
    "        loss.backward() # backpropagate to get values of the new weights\n",
    "        optimizer.step() # Take a step to update the newly calculated weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0\n",
    "\n",
    "\n",
    "PATH = './trained_model.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Training Our Network:\n",
    "<br>\n",
    "- We saved our trained model for future reference and usage. <br>\n",
    "- Now we test the trained model by exposing it to new data that it hasn't seen before to test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Number is: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download and load the training data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "label = labels[0]\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "#with torch.no_grad():\n",
    "img = img.to(dev) # Sending image to GPU\n",
    "label = label.to(dev) # Sending Label to GPU\n",
    "logits = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim=1)\n",
    "\n",
    "print('Actual Number is: {}'.format(label))\n",
    "helper.view_classify(img.view(1, 28, 28).cpu(), ps.cpu()) # Return Image and Tensor to CPU because numpy doesn't support GPU yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
